---
title: "Group Project"
author: "Rachel Lewis"
date: "2024-10-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Part A: Descriptive statistics
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(corrplot) 
library(reshape2)
library(factoextra)
library(caret)
library(class)
library(neuralnet)
```

# Introduction

Group: Tigers
Group names: Rachel, Paul, Nathan, Adil, William

In this group project, we will be analyzing tele-marketing data to predict the likelihood of success for tele-marketing calls. This assignment provides an opportunity to tackle a significant business challenge, giving us hands-on experience with real-world data from a bank's telemarketing campaign. Our goal is to develop insights into why the call center is underperforming and to create predictive models to address this issue.

The dataset for this project, tele.csv, reflects a real-world scenario where approximately 90% of the telemarketing calls fail to convert. This highlights the urgent need for optimization, which we aim to explore through data analytics.

## Get Data

```{r}
#read data from csv file
calls <- read.csv("tele.csv")
```

## Clean Data

We are removing the X, duration, and pdays variables. The x variablue only counts the amount of rows, the duration variable gives data about the call that we are trying to predict, and the pdays variable gives us information that we can get from poutcome and contact variables. We also factorized all the "character" variables and turned the response variable into a binary variable. 

```{r}
#delete columns X, duration, pdays
calls$X <- NULL
calls$duration <- NULL
calls$pdays <- NULL

#factorize char variables
calls$job <- as.factor(calls$job)
calls$marital <- as.factor(calls$marital)
calls$education <- as.factor(calls$education)
calls$default <- as.factor(calls$default)
calls$housing <- as.factor(calls$housing)
calls$loan <- as.factor(calls$loan)
calls$contact <- as.factor(calls$contact)
calls$month <- as.factor(calls$month)
calls$day_of_week <- as.factor(calls$day_of_week)
calls$poutcome <- as.factor(calls$poutcome)
#make response variable binary
calls$y <- ifelse(calls$y == "no", 0, 1)

#display cleaned data
str(calls)

#Turn into data frame
calls_dummy <- as.data.frame(model.matrix(~. -1, data = calls))

#Scale data
minmax <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

calls_scaled <- as.data.frame(lapply(calls_dummy, minmax))

#display scaled data
str(calls_scaled)
summary(calls_scaled)
```
## Calculate Breakeven percentage
For the Call center to break even, the cost per call must be equal to the return per call:

$Margin Per Call * x\:=\:VariableCostPerCall+\frac{TrainingCost}{RetentionRate+BonusRetetionRate}$

$10x\:=\:1+\frac{1000}{1000+10000x}$

$x=\frac{1}{5\sqrt{2}},\:x=-\frac{1}{5\sqrt{2}}$

since we are dealing with a probability, only the positive value is possible

$x=\frac{1}{5\sqrt{2}}=0.1414$

The breakeven percentage: 14.14%

## Visualize the Data


```{r}
# 1. Summary of the data
summary(calls)

# 2. Check class distribution of the target variable 'y'
y_dist <- calls %>%
  group_by(y) %>%
  summarise(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

# Plot the class distribution
ggplot(y_dist, aes(x = factor(y), y = percentage, fill = factor(y))) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(title = "Distribution of Target Variable (y)",
       x = "Outcome (0 = No, 1 = Yes)", y = "Percentage") +
  scale_fill_manual(values = c("red", "green")) +
  theme_minimal()

# 3. Visualize numeric features with respect to y
ggplot(calls, aes(x = age, fill = factor(y))) +
  geom_histogram(bins = 30, alpha = 0.6, position = "identity") +
  labs(title = "Distribution of Age by Outcome",
       x = "Age", y = "Count") +
  scale_fill_manual(values = c("red", "green"), name = "Outcome (y)") +
  theme_minimal()

# Calculate success rate by age
age_success <- calls %>%
  group_by(age) %>%
  summarise(success_rate = mean(y))  # Calculate the proportion of y = 1 for each age

# 4. Visualize success rate by age
ggplot(age_success, aes(x = age, y = success_rate)) +
  geom_line(color = "blue", size = 1) +
  geom_point(color = "darkred", size = 2) +
  labs(title = "Relative Success Rate by Age",
       x = "Age", y = "Success Rate (y = 1)") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))  # Show y-axis as percentages

# 5. Visualize Job, Education, Housing status, day of the weak and Loan status vs y

# Job vs Success Rate
ggplot(calls, aes(x = job, fill = factor(y))) +
  geom_bar(position = "fill") +
  labs(title = "Proportion of Success by Job Type",
       x = "Job Type", y = "Proportion") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Education vs Success Rate
ggplot(calls, aes(x = education, fill = factor(y))) +
  geom_bar(position = "fill") +
  labs(title = "Proportion of Success by Education Level",
       x = "Education Level", y = "Proportion") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Loan Status vs Success Rate
ggplot(calls, aes(x = loan, fill = factor(y))) +
  geom_bar(position = "fill") +
  labs(title = "Impact of Loan Status on Success",
       x = "Loan Status", y = "Proportion") +
  theme_minimal()

# Housing Status vs Success Rate
ggplot(calls, aes(x = housing, fill = factor(y))) +
  geom_bar(position = "fill") +
  labs(title = "Impact of Housing Status on Success",
       x = "Housing Status", y = "Proportion") +
  theme_minimal()

# Day of the Week vs Success Rate
ggplot(calls, aes(x = day_of_week, fill = factor(y))) +
  geom_bar(position = "fill") +
  labs(title = "Success Rate by Day of the Week",
       x = "Day of the Week", y = "Proportion") +
  theme_minimal()

# 6 Calculate success rate by number of campaign contacts
contacts_success <- calls %>%
  group_by(campaign) %>%
  summarise(success_rate = mean(y))  # Calculate the proportion of y = 1 for each contact count

ggplot(contacts_success, aes(x = campaign, y = success_rate)) +
  geom_line(color = "purple", size = 1) +
  geom_point(color = "darkgreen", size = 2) +
  labs(title = "Relative Success Rate by Number of Contacts",
       x = "Number of Contacts", y = "Success Rate (y = 1)") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))  # Show y-axis as percentages


# 7. Visualize the effect of month on the success rate
ggplot(calls, aes(x = month, fill = factor(y))) +
  geom_bar(position = "fill") +
  labs(title = "Success Rate by Month", x = "Month", y = "Proportion") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# 8. Analyze the impact of previous outcomes (poutcome) on y
ggplot(calls, aes(x = poutcome, fill = factor(y))) +
  geom_bar(position = "fill") +
  labs(title = "Impact of Previous Outcomes on Current Success",
       x = "Previous Outcome", y = "Proportion") +
  theme_minimal()
```

# Interpretation of visualization:

-The Target Variable y (if a call was successful) has an average of 11.27%. This means that we are below our break-even level - that is why we are not profitable.

-Looking at the distribution by age, we can see that the number of successes is highest for people around 25 and 40 years old. But in these age groups, there were also the most people called. Looking at Graph 3.1, we can see that success rate is actually lowest for these ages, the highest success rates are for people below 18 and above 60.
This goes along with the job types that are linked to the highest success rates. Students and retired people.

-There is a higher chance of success for illiterate people. That may also be people that either didn't learn how to read and write yet, or that are disabled. Looking at the summary we can deduce that the number of illiterate people must be quite low though, for it does not even appear as a listed factor there.

-We can see that loan status itself has absolutely no influence on success rates, neither has housing status.

-We can see that the call center's success rate is lower on mondays and fridays. If that has something to do with the call center's worker's work moral or with customers willingness to buy can't be determined yet.

-When looking at the graph plotting the relative success rate by number of contacts, we can quickly see that contacting people more often generally decreases the likelihood of having a successful call.

-There are differences between success rates in different months. In March, September, October and December there are  significantly higher success rates. This cannot be explained at this point,

-At last, it becomes clear that the success rate is significantly higher for people that prevoiusly bought our product. This shouldn't lead to the assumption though that we should always call the same people. Demand gets saturated and relative success diminishes with an increasing number of calls. Additionally, only a fraction of the people that got called had bought the product before. This is not a group we can heavily rely on.




# Part B

## Clustering
```{r, cache=TRUE}
# Load required libraries
library(tidyverse)
library(cluster)
library(factoextra)

# Step 1: Read and prepare the data
calls <- read.csv("tele.csv")

# Step 2: Data preprocessing
# Remove non-predictive variables
calls_clean <- calls %>%
  select(-duration, -pdays)  # Remove duration and pdays

# Create numeric version of target variable
calls_clean$y_numeric <- ifelse(calls_clean$y == "yes", 1, 0)

# Step 3: Prepare data for clustering
# Convert categorical variables to numeric
calls_numeric <- calls_clean %>%
  mutate(
    job_num = as.numeric(factor(job)),
    marital_num = as.numeric(factor(marital)),
    education_num = as.numeric(factor(education)),
    default_num = as.numeric(factor(default)),
    housing_num = as.numeric(factor(housing)),
    loan_num = as.numeric(factor(loan)),
    contact_num = as.numeric(factor(contact)),
    month_num = as.numeric(factor(month)),
    day_num = as.numeric(factor(day_of_week)),
    poutcome_num = as.numeric(factor(poutcome))
  )

# Select numeric columns for clustering
cluster_vars <- calls_numeric %>%
  select(age, job_num, marital_num, education_num, default_num,
         housing_num, loan_num, contact_num, month_num, day_num,
         poutcome_num, campaign, previous, emp.var.rate,
         cons.price.idx, cons.conf.idx, euribor3m, nr.employed)

# Scale the variables
cluster_vars_scaled <- scale(cluster_vars)

# Step 4: Determine optimal number of clusters
# Calculate WSS for different k values
wss <- sapply(1:10, function(k) {
  kmeans(cluster_vars_scaled, centers = k, nstart = 25)$tot.withinss
})

# Plot elbow curve
plot(1:10, wss, type = "b", 
     xlab = "Number of Clusters (k)", 
     ylab = "Within-cluster Sum of Squares",
     main = "Elbow Method for Optimal k")

# Step 5: Perform k-means clustering
set.seed(123)
k <- 4  # Based on elbow plot
kmeans_result <- kmeans(cluster_vars_scaled, centers = k, nstart = 25)

# Add cluster assignments to original data
calls_clean$cluster <- as.factor(kmeans_result$cluster)

# Step 6: Analyze clusters
# Calculate success rate by cluster
cluster_analysis <- calls_clean %>%
  group_by(cluster) %>%
  summarise(
    size = n(),
    success_rate = mean(y == "yes"),
    avg_age = mean(age),
    avg_campaign = mean(campaign),
    avg_previous = mean(previous)
  )

print("Cluster Analysis:")
print(cluster_analysis)

# Step 7: Calculate financial metrics
financial_metrics <- cluster_analysis %>%
  mutate(
    total_calls = size,
    successful_calls = round(size * success_rate),
    variable_cost = size * 1,  # $1 per call
    revenue = successful_calls * 10,  # $10 per successful call
    profit = revenue - variable_cost,
    ROI = (profit / variable_cost) * 100
  )

print("\nFinancial Metrics by Cluster:")
print(financial_metrics)

# Step 8: Visualize results
# Success rate by cluster
ggplot(calls_clean, aes(x = cluster, fill = y)) +
  geom_bar(position = "fill") +
  labs(title = "Success Rate by Cluster",
       x = "Cluster",
       y = "Proportion") +
  theme_minimal()

# Age distribution by cluster
ggplot(calls_clean, aes(x = cluster, y = age)) +
  geom_boxplot() +
  labs(title = "Age Distribution by Cluster",
       x = "Cluster",
       y = "Age") +
  theme_minimal()

# Campaign contacts by cluster
ggplot(calls_clean, aes(x = cluster, y = campaign)) +
  geom_boxplot() +
  labs(title = "Campaign Contacts Distribution by Cluster",
       x = "Cluster",
       y = "Number of Contacts") +
  theme_minimal()

# Step 9: Identify profitable clusters
breakeven_rate <- 0.1414  # As calculated in the case

profitable_clusters <- financial_metrics %>%
  filter(success_rate > breakeven_rate) %>%
  arrange(desc(ROI))

print("\nProfitable Clusters (Above Break-even Rate):")
print(profitable_clusters)

# Step 10: Profile the clusters
cluster_profiles <- calls_clean %>%
  group_by(cluster) %>%
  summarise(
    total_customers = n(),
    success_rate = mean(y == "yes"),
    avg_age = mean(age),
    avg_campaign = mean(campaign),
    most_common_job = names(which.max(table(job))),
    most_common_education = names(which.max(table(education))),
    most_common_marital = names(which.max(table(marital)))
  )

print("\nCluster Profiles:")
print(cluster_profiles)
```

Based on the clustering analysis, we are dividing the population into four distinct clusters. The clusters are characterized by different success rates, average ages, and campaign contact numbers. The financial metrics show that some clusters are more profitable than others, with a return on investment (ROI) above the break-even rate of 14.14%. The two profitable clusters (cluster 3 and 4) have success rates above the break-even rate, indicating that they are more likely to generate revenue than incur costs.

## Profitability calculation
```{r, cache=TRUE}
# Continuing from previous clustering analysis...

# Define cost and revenue parameters
cost_per_call <- 1  # Variable cost per call
revenue_per_success <- 10  # Revenue per successful call
training_cost_per_associate <- 1000  # Training cost per associate
base_retention_rate <- 1000  # Base number of calls before turnover
success_retention_boost <- 100  # Additional calls per 1% increase in success rate

# Calculate profitability metrics for different strategies
calculate_profitability <- function(data, selected_clusters) {
  # Filter for selected clusters
  selected_data <- data %>%
    filter(cluster %in% selected_clusters)
  
  # Calculate basic metrics
  total_calls <- nrow(selected_data)
  success_rate <- mean(selected_data$y == "yes")
  successful_calls <- sum(selected_data$y == "yes")
  
  # Calculate retention metrics
  success_rate_improvement <- success_rate - 0.1414  # Improvement over break-even
  retention_boost <- success_rate_improvement * 100 * success_retention_boost
  effective_retention_rate <- base_retention_rate + retention_boost
  
  # Calculate number of associates needed
  associates_needed <- total_calls / effective_retention_rate
  
  # Calculate costs
  variable_costs <- total_calls * cost_per_call
  training_costs <- associates_needed * training_cost_per_associate
  total_costs <- variable_costs + training_costs
  
  # Calculate revenue and profit
  total_revenue <- successful_calls * revenue_per_success
  total_profit <- total_revenue - total_costs
  
  # ROI and other metrics
  roi <- (total_profit / total_costs) * 100
  profit_per_call <- total_profit / total_calls
  
  # Return results
  return(data.frame(
    clusters = paste(selected_clusters, collapse=","),
    total_calls = total_calls,
    success_rate = success_rate,
    successful_calls = successful_calls,
    associates_needed = ceiling(associates_needed),
    variable_costs = variable_costs,
    training_costs = training_costs,
    total_costs = total_costs,
    total_revenue = total_revenue,
    total_profit = total_profit,
    roi = roi,
    profit_per_call = profit_per_call,
    effective_retention_rate = effective_retention_rate
  ))
}

# Identify profitable clusters (above break-even rate)
profitable_clusters <- cluster_analysis %>%
  filter(success_rate > 0.1414) %>%
  arrange(desc(success_rate))

# Calculate profitability for different targeting strategies
# 1. All clusters (current approach)
all_clusters_profit <- calculate_profitability(calls_clean, unique(calls_clean$cluster))

# 2. Only profitable clusters
profitable_only <- calculate_profitability(calls_clean, profitable_clusters$cluster)

# 3. Top performing cluster only
top_cluster <- profitable_clusters$cluster[1]
top_cluster_profit <- calculate_profitability(calls_clean, top_cluster)

# Combine results
strategy_comparison <- bind_rows(
  all_clusters_profit %>% mutate(strategy = "Current Approach (All Clusters)"),
  profitable_only %>% mutate(strategy = "Profitable Clusters Only"),
  top_cluster_profit %>% mutate(strategy = "Top Cluster Only")
)

# Print results
print("Strategy Comparison:")
print(strategy_comparison %>% 
  select(strategy, total_calls, success_rate, total_profit, roi, profit_per_call) %>%
  arrange(desc(total_profit)))

# Create visualizations of the strategies
# ROI Comparison
ggplot(strategy_comparison, aes(x = strategy, y = roi)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "ROI Comparison by Strategy",
       x = "Strategy",
       y = "ROI (%)")

# Profit per Call
ggplot(strategy_comparison, aes(x = strategy, y = profit_per_call)) +
  geom_bar(stat = "identity", fill = "darkgreen") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Profit per Call by Strategy",
       x = "Strategy",
       y = "Profit per Call ($)")

# Calculate projected annual metrics
annual_projection <- strategy_comparison %>%
  mutate(
    annual_calls = total_calls * (250/90), # Assuming 250 working days per year
    annual_profit = total_profit * (250/90),
    annual_training_costs = training_costs * (250/90)
  )

print("\nAnnual Projections:")
print(annual_projection %>% 
  select(strategy, annual_calls, annual_profit, annual_training_costs) %>%
  arrange(desc(annual_profit)))

# Calculate improvement metrics
baseline_metrics <- all_clusters_profit
improvement_summary <- strategy_comparison %>%
  mutate(
    profit_improvement = ((total_profit - baseline_metrics$total_profit) / 
                           abs(baseline_metrics$total_profit)) * 100,
    efficiency_improvement = ((profit_per_call - baseline_metrics$profit_per_call) / 
                              abs(baseline_metrics$profit_per_call)) * 100
  )

print("Improvement Summary:")
print(improvement_summary %>%
  select(strategy, profit_improvement, efficiency_improvement) %>%
  arrange(desc(profit_improvement)))
```
In order to make our call center profitable, we decided to choose the top two clusters that are above our breakeven percentage of 14.14%. With our current strategy, we are operating at a loss of -52,592.34 dollars. By choosing the top two clusters we would be profitable with 11697.97 dollars. The main underlying factor behind the success of the two clusters is if the person being called has bought our product before. While we could obtain more profit by only choosing the top cluster, that would decrease the number of total calls made from 14,199 to 9,887 which could present some risk from fewer calls going out.

# PartC: Supervised Predictive Modeling   

## Split and Train Data

```{r}
#create new data frame with 2 successful clusters
calls_scaled$cluster <- as.factor(kmeans_result$cluster)
calls_filtered <- calls_scaled %>%
  filter(!cluster %in% c(1, 2))
calls_filtered$cluster <- NULL

calls_dummy2 <- as.data.frame(model.matrix(~. -1, data = calls_filtered))
new_scaled_calls <- as.data.frame(lapply(calls_dummy2, minmax))
str(new_scaled_calls)
summary(new_scaled_calls)

#split and train
test_size <- .3*nrow(new_scaled_calls)
set.seed(12345)
test_rows <- sample(1:nrow(new_scaled_calls), test_size)
calls_test <- new_scaled_calls[test_rows, ]
calls_train <- new_scaled_calls[-test_rows, ]
```

## Logistic Model

```{r}
m1 <- glm(y ~ ., data = calls_train, family = "binomial")
summary(m1)

#predict model
p1 <- predict(m1, calls_test, type = "response")
summary(p1)

#evaluate model
p1bin <- ifelse(p1 > .4, 1, 0)
confusionMatrix(as.factor(p1bin), as.factor(calls_test$y), positive = "1")
```

## KNN Model

```{r}
#build model
left_col <- which(colnames(calls_train) == "y")
p2 <- knn(train = calls_train[, -left_col],
                       test = calls_test[, -left_col],
                       cl = calls_train[, left_col],
                       k = 101,
                       prob = TRUE)
summary(p2)

#evaluate model
confusionMatrix(as.factor(p2), as.factor(calls_test$y), positive = "1")
```

## ANN Model

```{r, cache=TRUE}
#build model
m3 <- neuralnet(y ~., data = new_scaled_calls, hidden = 1, stepmax = 1e8, lifesign = "full")
plot(m3)

#predict model
p3 <- predict(m3, newdata = calls_test)
summary(p3)

#evaluate model
p3bin <- ifelse(p3 > .4, 1, 0)
confusionMatrix(as.factor(p3bin), as.factor(calls_test$y), positive = "1")
```
# Combined Model

## Build and Predict Combined Model

```{r}
#combine predictions
p_combined <- as.data.frame(cbind(p1bin, p2, p3bin))
```

## Evaluate Combined Model

```{r}
p_final <- apply(p_combined, 1, function(x) {
  ifelse(sum(x == 1) > length(x) / 2, 1, 0)
})
confusionMatrix(as.factor(p_final), as.factor(tele_test$y), positive = "1")
```
## Evaluation of the Models

In the context of this data, a "0" indicates an unsuccessful call and a "1" means a successful telemarketing call. With this in mind, we would want a model that is best able to predict who will be successful when we call them. This means that we would also want to minimize false positives where we predicted "Success" but the actual outcome was "No Success". These are customers who were predicted to be interested but ended up not being interested. In order to save our time and money, we would want to ensure that we spend our time calling people who will actually be a "Success" or a 1. By calling these people, we could also potentially be pushing them further away from our business. This is measured by the sensitivity of the models. We want the model to be both highly accurate and sensitive, which is measured by testing data. 

With this in mind, after evaluating the three models of Logistic Regression, KNN, and ANN, the combined model yields the best predictive performance. By combining the strengths of each individual model, the combined approach effectively enhances accuracy and sensitivity, making it the most reliable choice for predicting analytics. With a high acuracy rate and the highest senstivity rate of each of the models, the combined model yields the best results. 

